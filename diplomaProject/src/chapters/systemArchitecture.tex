\chapter{System Architecture and Workflow}
\label{chapter:system-architecture}

In the following sections we are going to talk about the various architecture and technology choices.

Also, we are going to present the workflows of the system.

\section{Recommendation System Architecture} 
\label{sec:architecture}

\begin{figure}[h]
\caption{System Architecture}
\includegraphics[width=1.0\textwidth]{src/img/architecture.png}
\end{figure}

\subsection{Programming languages}
\label{sec:programming-languages}
There were a multitude of programming languages to chose from.
In the following subsections we are going to discuss what languages we chose, why and for what purpose.

\subsubsection{Java}
\label{sec:programming-languages-java}
Java is a general purpose language that is class based, object oriented and concurrent. 
It is designed to have as few implemmentation dependencies as possible and be a "write once, run anywhere" type of language, meaning that compiled java code can run on all platforms that support java, without the need of recompilation.
Java applications are typically compiled to bytecode that can run on any Java virtual machine (JVM) regardless of the computer architecture.
\\ It is a language that supports multiple paradigms, as:  object-oriented, structured, imperative, functional, generic, reflective, concurrent. In our implemmentation we used the imperative, object-oriented and concurrent paradigms. By combining the object-oriented and imperative paradigms we managed to obtain a well structured and easy to read code base. By using the concurrent paradigm we are taking full advantage of the current multi-core arhitectures.
\\ Another reason for choosing Java is the great community and documentation. At the time of writing this document, Java was the most used language in the industry. Due to this, we can easily find support and documentation on any framework and problem we may stumble upon during the implemmentation of this system. Also, a great variety of frameworks exist for this language.

\subsubsection{Javascript}
\label{sec:programming-languages-javascript}
Javascript is a high level, dynamic, untyped and interpreted programming language. Alongside CSS and HTML, Javascript is one of the pillars of the current World Wide Web. In the last couple of years it has gained a great popularity in the detriment of action script, which was a programming language for the Adobe Flash Player. This movement towards Javascript is also because most mobile devices do not support Adobe Flash Player.
\\ Even though, Javascript may also be used as a backend programming language, since the launch of Node.js, which is  an open source, cross-platform runtime environment for server-side and networking applications, the most commonly usage of Javascript is as a client side scripting language. This means that the Javascript code is send along with the HTML to the browser, which then interprets it. A great advantage is the fact that the execution of the javascript code is done on the client, thus, in order to use it you just need to serve a file to the client.
\\ In our implemmentation we used Javascript and Node.js to create a demo application which easily integrates with our Recommender System. Javascript was used to create the graphical user interface, since we have an abundance of frameworks that enable us to create a quick and beautiful user interface. Because of various security issues, Javascript is not allowed to make cross domain requests, so Node.js was used in order to create a proxy between our Recommender System and the Javascript client. Also, Node.js was used to serve the files to the client.
\\ Also, in order to better show our Recommender System's capabilities, a Chrome plugin was built that could easily integrate with Adobe's existing platform.
\\ Since, Javascript is one of the pillars of the World Wide Web and our Recommender System was meant to easily integrate with a web application, Javascript was the first choice for our demo applications.


\subsection{Frameworks}
\label{sec:frameworks}
A framework is like a black box that offers certain functionalities to it's user and does not require him to have any knowledge of what is going on behind the scenes
The basic principle of a framework is: Not having to reinvent the wheel. By using them we can build faster and better software.
\\ Faster, because it allows the programmer to focus on implemmentation specific code, while re-using generic modules, without being tied to the framework itself.
\\ Better, because a framework ensures you that the code you are running is in full compliance with the industry's rules. It is structured, and both upgradable and maintanable.

\subsubsection{Spring Framework}
\label{sec:frameworks-spring-framework}

\subsubsection{Apache HBase}
\label{sec:frameworks-hbase}
Hbase is an open source, non relational and distributed databse, modeled after Google's Big Table. It is written in Java, which is a great advantage, since it is really easy to integrate with our existing code.
\\ Unlike realational databases, the structure of a non relational database is very simillar to that of a hash map. This grants us an easier control over the content of the database and faster access time. Most of the operations can be done in constant time. HBase also has an api that supports multiple types of queries, simillar in functionality to those of a SQL database.
\\ Since HBase is a distributed database, it also obeys the CAP theorem, also known as Brewer's theorem, which states that it is impossible for a distributed system to provide all of the following:

\begin{itemize}
	\item Consistency - The same data is seen by all nodes at the same time.
	\item Availability - If a number of nodes from your cluster fail, then the system will still be available.
	\item Partition tolerance - The system will continue to operate, even if the cluster has been split into multiple partitions, that are unable to exchange messages, due to network failures.
\end{itemize}

Hbase has appeared due to the need of processing massive amounts of data for the purpose of language processing and is a CP type system. 
\\ Since, we needed a fast and reliable database, that could process the large amounts of text data that we obtained from our articles and which could easily be integrated with Java, HBase was the right choice for our recommender system. Another reason for chosing HBase was the fact that it has a great community and support. 

\subsubsection{Stanford CoreNLP}
\label{sec:frameworks-stanford-corenlp}
Stanford CoreNLP provides us with a set of NLP processing tools. Even though, this is a powerful tool, capable to give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize dates, times, and numeric quantities, and mark up the structure of sentences in terms of phrases and word dependencies, indicate which noun phrases refer to the same entities, indicate sentiment, etc we use only a small part of it's capabilities.
Stanford CoreNLP is an integrated framework which can be used with ease and we can choose what tools to enable or disable by setting the options given to the framework. 
From all the existing options we use only the tokenize, ssplit, pos, lemma.

tokenize
Tokenizes the text. This component started as a PTB-style tokenizer, but was extended since then to handle noisy and web text. The tokenizer saves the character offsets of each token in the input text, as CharacterOffsetBeginAnnotation and CharacterOffsetEndAnnotation.

ssplit 
Splits a sequence of tokens into sentences.

pos
Labels tokens with their POS tag
A Part-Of-Speech Tagger (POS Tagger) is a piece of software that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc., although generally computational applications use more fine-grained POS tags like 'noun-plural'. This software is a Java implementation of the log-linear part-of-speech taggers described in these papers (if citing just one paper, cite the 2003 one):
The tagger was originally written by Kristina Toutanova. Since that time, Dan Klein, Christopher Manning, William Morgan, Anna Rafferty, Michel Galley, and John Bauer have improved its speed, performance, usability, and support for other 
languages.

The system requires Java 1.8+ to be installed. Depending on whether you're running 32 or 64 bit Java and the complexity of the tagger model, you'll need somewhere between 60 and 200 MB of memory to run a trained tagger (i.e., you may need to give java an option like java -mx200m). Plenty of memory is needed to train a tagger. It again depends on the complexity of the model but at least 1GB is usually needed, often more.

lemma
Generates the word lemmas for all tokens in the corpus.

\begin{itemize}
	\item Present Spring and why we chose it	
	\item Present Java and why use chose it
	\item Present HBASE and why we chose it( not sure about this. Small presentation in database design. Can bring it from there)
	\item Present Stanford lemmatizer and why we chose it.	
\end{itemize}


\section{Recommendation System Workflow} 
\label{sec:workflow}
There are multiple actions that you can request from the recommendation system through the Spring RESTful api.
\\ In the following sections we are going to talk about the implemented use cases.
\\ All the data will be returned as a JSON object.

\hfill \break
\hfill \break
\hfill \break
\hfill \break

\begin{figure}
\caption{System Workflow}
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{src/img/workflow.png}
\end{figure}

\subsection{Add user}
\label{sec:workflow-add-user}
A PUT request is made to the RESTful api with the required data for adding a friend of an user.
\\The minimum data required for a user is the user id and friend id.
\\The request is intercepted by the api and the new friend is added to the user’s top friends list. If the operation is successful then the user will receive “true”, otherwise the user will be informed of the error. 

\subsection{Add user friend}
\label{sec:workflow-add-user-friend}
A PUT request is made to the RESTful api with the required data for adding a friend of an user.
\\ The minimum data required for a user is the user id and friend id.
\\ The request is intercepted by the api and the new friend is added to the user’s top friends list. If the operation is successful then the user will receive “true”, otherwise the user will be informed of the error. 

\subsection{Add user direct recommendation}
\label{sec:workflow-add-user-direct-recommendation}
A PUT request is made to the RESTful api with the required data for adding a direct user recommendation.
\\ These are supposed to be recommendations made manually by a user.
\\ The minimum data required is the user id and an item id.
\\ The request is intercepted by the api and the user entry is fetched from the database and the new item is added to the items directly recommended list of the user. If the operation is successful then the user will receive “true”,otherwise the user will be informed of the error. 

\subsection{Delete user}
\label{sec:workflow-delete-user}
A DELETE request is made to the RESTful api with the required data for deleting an user.
\\ The minimum required data is the user id
\\ The request is intercepted by the api and the database entry is deleted. If the operation is successful then the user will receive “true”, otherwise the user will be informed of the error. 


\subsection{Update user article history}
\label{sec:workflow-update-user-article-history}
A PUT request is made to the RESTful api with the required data for updating an user article history
\\ The read article history can be updated and a rating of a certain article can be added. 
\\ The minimum required fields are the article id and the user id.
\\ The request is intercepted by the api and the user entry is fetched from the database. The new item is added to the article history list of the user. If the operation is successful then the api will return “true”, otherwise the user will be informed of the error. 


\subsection{Article recommendations based on friends direct recommendations}
\label{sec:workflow-friends-direct-recommendations}
A GET request is made to the RESTful api with the user id.
\\ The request is intercepted by the api and all the directly recommended articles of the top friends of the user are returned.
\\ The top friends list can be added manually through the api.
\\ If a top friends list does not exist, one will be generated by using the user’s previous article history.
\\ If the operation is successful then the user will receive “true”, otherwise the user will be informed of the error. 

\subsection{Add article}
\label{sec:workflow-add-article}
A PUT request is made to the RESTful api with the required data for adding a new article.
\\ The request is intercepted by the api and the new article is added to the database.
\\ The minimum required data is the article id.
\\ If the operation is successful then the user will receive “true”, otherwise the user will be informed of the error.


\subsection{Get all articles}
\label{sec:workflow-get-all-articles}
A GET request is made to the RESTful api in order to get all the articles.
\\ The user may specify how many articles he wishes to receive.
\\ The articles are fetched from the database and returned to the user.
\\ If the operation is successful then the user will receive the article list, otherwise the user will be informed of the error

\subsection{Get recommended articles}
\label{sec:workflow-get-recommended-articles}
A GET request is made to the RESTful api in order to get the recommended articles for a user
\\ The minimum required data is the user id for whom we need the recommendation.
\\ The system will try to guess how the user will rate the articles in the database, based on his previous ratings and the ratings of the other users he has the most common interests.
\\ If the operation is successful then the user will receive the top rated articles, otherwise the user will be informed of the error.

\subsection{Get related articles}
\label{sec:workflow-get-related-articles}
A GET request is made to the RESTful api in order to get the related articles for an article.
\\ The minimum required data is the article id for which we need the related articles. The user may also specify a max number of articles to be returned
\\ The system intercepts the request and will use all the similarity methods from the presented workflow to calculate the similarity between every article in the database and the current article.
\\ Each article will have a value from 0 to 1 meaning the similarity with the article for which we requested the related articles.
\\ The top related list is returned is if the operation is successful, otherwise the user will be informed of the error.


\subsection{Get articles related to a collection}
\label{sec:workflow-get-articles-related-to-collection}
A GET request is made to the RESTful api in order to get the related articles for  a collection.
\\ The minimum required data is the collection article list.
\\ By using the previous presented process of getting an article’s similarity score to another article, we get the similarity score of all the articles to all the collection articles. We sum up this scores and return the articles with the top similarity score, if the operation was successful, otherwise the user will be informed of the error.

\subsection{Integration with chrome plugin}
\label{sec:workflow-integration-with-chrome-plugin}
If the articles in the current publication do not exist in the database, then the chrome extension will add them by doing specific requests to the application api.
\\ Once all the articles have been added, the user may start a view in which he can see the related articles.


\begin{itemize}
	\item Add the workflow
	\item Add all the workflows(use cases) and explain them in depth
\end{itemize}